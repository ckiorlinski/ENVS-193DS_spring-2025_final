---
title: "Final"
author: "Christopher Kiorlinski"
date: "6/8/2025"
format:
  html:
    toc: true # use this to display a table of contents
execute:
  message: false # use this to make sure messages don't show up
  warning: false # use this to make sure warnings don't show up
---

**Repository:** <https://github.com/ckiorlinski/ENVS-193DS_spring-2025_final.git>

# Set up

```{r packages-and-data}
# reading in packages
library(tidyverse) # general use
library(here) # file organization
library(janitor) # cleaning data frames
library(gt) # table making
library(readxl) # reading excel files
library(ggeffects) # getting model predictions
library(dplyr)
library(MuMIn)

sst <- read.csv("data/SST_update2023.csv")

nest_boxes <- read.csv("data/occdist.csv")

```

# Problem 1: Research Writing

## a.

In part 1, they used a Pearson's correlation test to how the two variables relate to/are associated with each other; the variables in this case being distance from headwater (km) and annual total nitrogen load (kg year-1). In part 2, they used a one way ANOVA test to compare the means of more than two groups to identify if there is a significant difference based on one independent variable. The independent variable in this case is average nitrogen load and the variance of mean between sources are being compared.

## b.

The effect size is a relevant piece of information that should have been included in summary of part 2 because it demonstrates the practical significance of results alongside the calculated p value. While a significant p-value shows that a difference exists, effect size demonstrates whether that difference is meaningful and impactful in the real world. Although we know there is a significant difference in the mean nitrogen load between all sources, we do not know the strength of the relationship between variables.

Another piece of information that should have been included in part 2 is the confidence intervals. Having the confidence interval provides crucial context to the result that makes it much easier to quanify and understand without looking at the raw data. In this case, we know that there is some sort of difference in the mean nitrogen load between all sources, we do not know the actual difference in units.

## c.

Part 1:

We found a (Relationship Strength) (Pearsons r) relationship between distance from headwater (km) and annual total nitrogen load (kg year^-1) (F(Degrees of Freedom) = test statistic, p = .03, $\alpha$ = confidence level).

Part 2:

We found a (size) difference (n\^2 = Effect size) between sources in average nitrogen load (kg year\^-1) (one-way ANOVA, F(Among Groups DF, Within Groups DF) = Test Statistic, p = .02, $\alpha$ = confidence level).

On average, urban land had less nitrogen load than grasslands (Numeric difference, Confidence Interval), and more than wastewater (Numeric difference, Confidence Interval), etc


# Problem 2: Data visualization

## a.

```{r}

sst_clean <- sst |> 
  mutate(date = ymd(date)) |> 
  mutate(
    year  = factor(year(date)),
    month = factor(month(date, label = TRUE, abbr = TRUE), 
                   levels = month.abb)
  ) |> 
  group_by(year, month) |> 
  summarise(
    mean_monthly_sst = round(mean(temp, na.rm = TRUE), 1),
    .groups = "drop"
  )

slice_sample(
  sst_clean, # data frame
  n = 5 # showing 5 rows
)


str(sst_clean)


```

## b.

```{r}

monthly_sst <- sst_clean |> 
   filter(as.integer(as.character(year)) %in% 2018:2023)

ggplot(monthly_sst, aes(x = month, y = mean_monthly_sst, group = year, color = year)) +
  geom_point() +
  geom_line(size = 1) +
  labs(
    x = "Month",
    y = "Mean Monthly Sea Surface Temperature (Â°C)"
  ) +
  scale_color_manual(
        values = c(  "2018" = "#FFD580",  # brighter light orange
  "2019" = "#FFB347",  # soft orange
  "2020" = "#FF9933",  # medium orange
  "2021" = "#FF8000",  # standard orange
  "2022" = "#CC6600",  # dark orange
  "2023" = "#993D00"   # very dark burnt orange
  )) +
  theme_minimal() +
  theme(
panel.background = element_blank(),
panel.grid = element_blank(), #no grid
    axis.ticks = element_line(color = "black"),
    axis.line = element_line(color = "black"),
plot.title = element_text(hjust = 0),
legend.position = c(0.1, 0.7),
legend.background = element_blank() #no legend
)

```


# Problem 3: Data analysis

## a.

The binary code in this table corresponds with the type of bird that the researchers have decided inhabits that specific nest box based on characteristics such as eggs and foliage used for nest creation. Each column, titled with a one or two letter shorthand, represents the types of birds in the study, such as "sp" for swift parrot. A zero represents that this bird was not in this nest box, whilst a one represents that this bird was present at this nest box.

## b.

What sets apart the swift parrot in this study is the fact that they are highly nomadic and do not breed in the same place in successive years. This leaves the nest boxes open for competitors to inhabit, as boxes can be left vaccant if food is not available in the immediate area.

## c. 

The seasons refereed to in the study reference two distinct food producing tree flowering episodes during 2016 and 2016. The sudden influx of food for the swift parrot induces a mass nesting of the birds in the immediate area. The study compares the nesting patterns between the two events.

## d. 

4 models total:

| Model number | SzN | Distance to Forest Edge | Predictor list              |  
|:------------:|:---:|:-----------------------:|:---------------------------:|  
| 0            |  0  |            0            | no predictors (null model)  |
| 1            |  1  |            1            | all predictors (full model) | 
| 2            |  1  |            0            | Season only                 |   
| 3            |  0  |            1            | Distance only               |  

## e.

```{r}

# Model 0: null model
model0 <- glm(
  sp ~ 1,
  data = nest_boxes,
  family = binomial
)

# Model 1: all predictors
model1 <- glm(
  sp ~ edge.distance + season,
  data = nest_boxes,
  family = binomial
)

# Model 2: season only
model2 <- glm(
  sp ~ season,
  data = nest_boxes,
  family = binomial
)

# Model 3: edge distance only
model3 <- glm(
  sp ~ edge.distance,
  data = nest_boxes,
  family = binomial
)


```

## f.

```{r}
# Simulate residuals
res0 <- simulateResiduals(model0)
res1 <- simulateResiduals(model1)
res2 <- simulateResiduals(model2)
res3 <- simulateResiduals(model3)

# Plot diagnostics
plot(res0, main = "Model 0 Diagnostics")
plot(res1, main = "Model 1 Diagnostics")
plot(res2, main = "Model 2 Diagnostics")
plot(res3, main = "Model 3 Diagnostics")
```


# Problem 4: Affective and explanitory visualizations

## a.

The visualizations are completely different in the way that I have represented my data. My categorical visualization was organized into boxplots with a jitter, while my continuous visualization was mistakenly a line chart, which did not work with my variable. My final visualization from homework 3 was much more abstract, with the jitterplot points being represented by dendrites on a neuron and the error bar being the length of the axon.

Both of the maps that I created for Homework 2 contain several specific aspects that translated over to my final visualization, but overall the representations are very different. For the categorical visualization, I pulled the categorical aspect by changing my continuous sleep time variable into a categorical bin. I used the data type, reaction time vs sleep time, from my continuous visualization.

Although my first two visualizations from homework 2 were interesting in their own rights, they suffered from a lack of data which hampered their usability. My categorical visualization investigated an aspect of my data recording that I wish I could have looked at more, which was reaction time versus self recorded stress level for the data, which showed an interesting pattern of low and high stress having slower reaction time, while middle stress levels had faster reaction times. The continuous visualization showed the same general trend as my final visualization, where low sleep had slow reaction speed with some increases in the high sleep times.

I did not go to workshop during week 9 for various reasons, but I got really good feedback from my peers during workshop in week 10. Honestly, looking back at my final work, it does not make as much sense as I would have liked even if I think I killed the theme of the neurons. I would try and figure a better way to make the points on my visualization correlate with the actually data.